{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this experiment, we are going to visualize the uncertainty of a deep neural network by\n",
    "using dropout as a mean of Bayesian Approximation [[1]](https://arxiv.org/abs/1506.02142).\n",
    "\n",
    "We are going to use the [monkey species dataset from Kaggle](https://www.kaggle.com/slothkong/10-monkey-species).\n",
    "If you want to run this notebook, clone it in your Colab, get your Kaggle API key,\n",
    "upload it on your Colab, download the Kaggle monkey dataset and start cracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -q kaggle\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where you upload your Kaggle API JSON file.\n",
    "Steps to do that: Go to your Kaggle account and look for API token generation section.\n",
    "Expire your previous tokens (if you any of them) and then, create a new token. You can\n",
    "just create a new token without expiring your previous tokens if you wish too.\n",
    "This will download a `Kaggle.json` file. Upload this file in the following step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell and press Browse to upload Kaggle.json file\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download local copy of monkey dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle\n",
    "! mv kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download -d slothkong/10-monkey-species\n",
    "! mkdir monkey_dataset\n",
    "! unzip 10-monkey-species.zip -d monkey_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable eager execution for K.function() with learning_phase to work properly\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Network\n",
    "from plotting import plot_grid, visualize_probdist\n",
    "from dataset import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dir = 'monkey_dataset/training/training'\n",
    "test_dir = 'monkey_dataset/validation/validation'\n",
    "\n",
    "# The CSV file contains spaces for data fields and column names which we need to remove.\n",
    "monkey_labels = pd.read_csv(\"monkey_dataset/monkey_labels.txt\")\n",
    "monkey_labels.columns = [c.strip() for c in monkey_labels.columns]\n",
    "monkey_labels['Label'] = monkey_labels['Label'].str.strip()\n",
    "monkey_labels['Common Name'] = monkey_labels['Common Name'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training and Testing Data Count Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.bar(range(len(monkey_labels['Train Images'])), monkey_labels['Train Images'])\n",
    "plt.bar(range(len(monkey_labels['Validation Images'])), monkey_labels['Validation Images'])\n",
    "plt.xticks(range(len(monkey_labels['Common Name'])), monkey_labels['Common Name'], rotation=90)\n",
    "plt.xlabel('Monkey Types')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training and Testing Data Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Monkeys in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Class Folder Name]: [Common Name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(rows=2, cols=5, figsize=(16,8),\n",
    "          image_root_path=train_dir, labels=monkey_labels, data_shape=IMAGE_SHAPE[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train some classes of monkeys and see how our model performs for classes of monkeys which it was never trained before (testing out of distribution uncertainty). But this is not as extreme as testing out on completely different looking data samples (like objects, and other animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting classes of monkey to train\n",
    "class_filter = ['n0', 'n1', 'n2', 'n3', 'n4']\n",
    "label_mapping = monkey_labels['Common Name'][:5].to_dict() # Get class folder name -> common name mapping by taking the first five rows from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 443 images belonging to 5 classes.\n",
      "Found 0 images belonging to 5 classes.\n",
      "Found 137 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(path=train_dir, target_size=IMAGE_SHAPE[:2], dataset_type=Dataset.TRAIN,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        class_filter=class_filter,\n",
    "                        label_mapping=label_mapping)\n",
    "\n",
    "val_dataset = Dataset(path=train_dir, target_size=IMAGE_SHAPE[:2], dataset_type=Dataset.VAL,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        class_filter=class_filter,\n",
    "                        label_mapping=label_mapping)\n",
    "\n",
    "test_dataset = Dataset(path=test_dir, target_size=IMAGE_SHAPE[:2], dataset_type=Dataset.TEST,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       class_filter=class_filter,\n",
    "                       label_mapping=label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(input_shape=IMAGE_SHAPE, dropout_rate=0.2, num_classes=len(class_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "14/13 - 31s - loss: 1.7165 - accuracy: 0.2122\n",
      "Epoch 2/2\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "14/13 - 29s - loss: 1.5480 - accuracy: 0.3341\n"
     ]
    }
   ],
   "source": [
    "net.train_model(train_dataset, val_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_preds = net.model.predict(test_dataset.datagenerator)\n",
    "y_preds = np.argmax(y_prob_preds, axis=1)\n",
    "\n",
    "label_test = test_dataset.datagenerator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76        26\n",
      "           1       0.42      0.36      0.38        28\n",
      "           2       0.71      0.37      0.49        27\n",
      "           3       0.40      1.00      0.57        30\n",
      "           4       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.50       137\n",
      "   macro avg       0.46      0.49      0.44       137\n",
      "weighted avg       0.46      0.50      0.44       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ark/anaconda3/envs/tensorflow/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_test, y_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
